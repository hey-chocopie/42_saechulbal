# 1. 학습 날짜

* 2020-12-04(월)

# 2. 학습시간

* 17:00 ~ 22:00(이노베이션 아카데임 클러스터)

# 3. 학습 범위 및 주제

* 머신러닝에 대해서 공부해보자. 

 # 4. 동료 학습 방법

해당 사항 없음.

# 5. 학습 목표

# lec1 요약

* ai관련해서 공부를 해보기로 결정햇따. 



linear regressio, logistic regression
두가지에 대해서 공부해보기. 

머신러닝 툴로는 
텐서플로우와 파이썬으로 진행 될계획이다. 

* 강의 링크는 사진으로..

* 머신러닝이란 무엇인가?
  기본적인 프로그래밍은 explicit라는 프로그래밍이라고 부르는데, 스팸메일이나, 자율주행차 등 explicit하지 않는 경우에서 일일이 프로그래밍을 하기엔 너무 많은량의 조건을 주어야함.

  이를 해결하기위해서 컴퓨터 스스로 학습하여, 프로그래밍 하도록 만들어 준걸 머신 러닝이라고 함. 

> 이 머신 러닝에서 supervised러닝과 비 supervised러닝이 있다.
 
  supervised러닝의 경우 많은 데이터를 넣어서 그 데이터를 가지고 학습하는걸 supervised러닝이라고 한다. 
# # supervised러닝 종류. 

1. regression : 예를 들어 0~100 까지의 넓은 결과값을 같는것중 하나를 예측
2. binary classification : pass/non 두가지 중에 하나를 결정 분류
3. multi-label classfication : abcef 중에서 하나를 선택 분류

# lec1 예제.

linear regression에서 학습하는 방법을 알아보자. 

* 모두의 딥러닝강의에서는 tensorflow로 예제를 진행한다.
> tensorFlow의 장점. 
사용자가 많고, 참조할수 있는 소스파일이 많음. 

예제 풀기. 

<pre><code>import tensorflow as tf
hello = tf.constant("Hello, Tensorflow!")
sess = tf.Session()
print(sess.ren(hello))</pre></code>

<pre><code>Traceback (most recent call last):
  File "C:/Users/pc/PycharmProjects/untitled2/test.py", line 5, in <module>
    sess = tf.Session()
AttributeError: module 'tensorflow' has no attribute 'Session'</pre></code>

강의에서 나오는 코드 그대로 입력을하게 되면 위의 글처럼 에러가 나오게 되는데, 교수님이 진행하신, 강의에선 1.x 버전의 tensolflow 였고, 현재 사용되는 버전은 2.x로 넘어가면서, session 대신 

<pre><code>
import tensorflow as tf
hello = tf.constant("Hello, Tensorflow!")
tf.print(hello)</pre></code>

위와 같은 형태로 바꾸어주면 정상적으로 출력이 진행된다. 

약간에 설명을덧 붙이자면, constant를 통해 노드를 만들고,printf 를 통해 콘스턴트를 출력하는 것이다. 

> 영상에 나오는 대부분의 강의가, tensorflow 1.xxx 버전에 맞추어 짜여져 있다. 
> 



* 정수 출력. 
  
  다음으로 정수 출력에 대해 알아본다면, 
  import tensorflow as tf

<pre><code>node1 = tf.constant(3.0, tf.float32)
node2 = tf.constant(4.0)
node3 = tf.add(node1, node2)

print("node1:", node1, "node2:", node2)
sess = tf.Session()
print("sess.run(node1,node2):", sess.run([node1, node2]))</pre></code>

위처럼 콘텐트로 노드를 만들고, session을 이용해 문자를출력햇다. 

위의 예제도 똑같이 버전이 바뀌면서 2.x 버전에서는,

<pre><code>import tensorflow as tf
node1 = tf.constant(3.0, tf.float32)
node2 = tf.constant(4.0)
node3 = tf.add(node1, node2)
tf.print(node1, node2)</pre></code>

이렇게 간단한 형태로 출력이 가능하다. 

* 용어정리. 
tensor은 [1,2,3] 이런 형태의 배열을 의미한다. 
tensor ranks  라는 말은 몇 차원의 배열인가. 

s = 483 0차원,
s = [1, 2 , 3] 1차원 배열
tensor shape
[a] = 1차원 shape
[a,b] = 2치원 shape
[a,b,c] = 3차원 shape

다음으로는 

* 용어 정리
  linear 은 일정한 비율로 증가하거나 감소하는 상황을 일컫는다.

  cost function 일정한 비율로 증가하는 함수를 맞출떄 일치하지 않는 함수가 있다면 그 함수와 원래 나와야 하는 함수 값을 비교하는 것을 cost function이라고 한다. 

  결국 우리가 구할려고 하는 것은 cost를 최대한 적게 하는 것을 구하는것을 목표로 한다. 



![Image](~/../../mnt/c/Users/pc/Desktop/ai/aa.PNG)

자자 진정하고 다시 보자. 
다시 cose구하는 공식으로 돌아오게 된다면, 

x값이 바뀔떄마다, 기울기에 해당한느 값도 바뀌고, y의 결과 값도 바뀐다. 이 차이를 빼게되면 오차률을 구할수 있게 되는데, 우리는 오차률의 크기만 필요하고 제곱으로 절대값을 더 크게 만들어 주면, 좀더 차를 정확하게 구할수 있다. 고로 우리는 이 값을 제곱으로 치환해준다. 

그리고 x 값에 따른 차를 더해주고 나누어 주게되면 평균적으로 오차률인 cost 의 값을 구할수 있게 된다. 

결국 이 cost 의 값이 작아지게 되었을때 우리가 원하는 값과 거의 일치하게 된다 .

이과정을 우리는 알고리즘으로 구하게 해주어야한다. 

일반적으로 사용되는 방법은, 
gradient descent algorithm 이다. 
경사 내려감 알고리즘 

* gradient descent algorithm
  설명: 경사도가 낮은 곳으로 이동을 하면서 결국에는 경사도가 가장 작은곳으로 이동하게 되는 알고림즘이다. 

  특징 
  1. minimize cost 하는 과정에서 사용이 되고 
  2. 많은 머신러닝에서 미니마이즈 하는 과정에 사용
  3. 많으 값들이 있는 cost도 minimize할수 있다. 
   
   gradien descent 를 사용할떈 cost funtion이 convex function 모양인 지 확인 을 해야한다. 그 이유는 cost의 위치에 따라 결과 값이 다르게 나올수 있는데, convex funtion의 모양이 나오는 linear 에서는 항상 값이 같으므로 gradien를 사용할수 있다. 

넘어가기 전에 hypothesis 를 한번 더 살펴보고 가자.  이미지 3


오른쪽의 기울기는 +이다, 그런데, 이 W를 왼쪽으로 옮길려면, 왼쪽으로 이동해야하고, 왼쪽의 기울기는 마이너스 이인데, 오른쪽으로 이동해하므로, 


이미지, 4

W := W - 기울기 
위의 식이 나오게 된다. 

이미지 5


이미지 6
이를 공식으로 푸렬면 위의 공식처럼 하면되는데,
여기서 기억해둘건 ,
learning_rate 는 배우기 위한 단위 이므로 임의의 수를 넣어주면 된다. 작을 수록 정확한 수가 나온다.

마지막에 W.sssign은 그냥 w 값을 새로 정읳나다고 생각하면된다.

<pre><code>
import numpy as np
import tensorflow as tf

x_train = [1, 2, 3, 4]
y_train = [0, -1, -2, -3]

tf.model = tf.keras.Sequential()
# 시퀀시라는 모델을 할당하겠다고 선언하는것,
# Sequential 모델은 각 레이어에
# 정확히 하나의 입력 텐서와 하나의 출력 텐서가 있는 일반 레이어 스택에 적합합니다.

# units == output shape, input_dim == input shape
tf.model.add(tf.keras.layers.Dense(units=1, input_dim=1))
# add 계층을 스택에 쌓는다.
sgd = tf.keras.optimizers.SGD(lr=0.1)  # SGD == standard gradient descendent, lr == learning rate
tf.model.compile(loss='mse', optimizer=sgd)  # mse == mean_squared_error, 1/m * sig (y'-y)^2

# prints summary of the model to the terminal
tf.model.summary()

# fit() executes training
#fit x,y 입력값에 따른 트레이닝 시작. 
tf.model.fit(x_train, y_train, epochs=200)

# predict() returns predicted value
y_predict = tf.model.predict(np.array([5, 4]))
# predict 입력샘플에 대한, 출력값
print(y_predict)</pre></code>

