lectuere 12 

뉴런네트워크의 꽃 RNN recurrent neural Network

우리가 사용하는 데이터에는 시퀀시 데이트가 많다. 

시퀀시 예) 예를 들어, "오늘도 좋은 하루 입니다." 라는 단어가 잇으면, 좋은 이란 단어만으로 모든 문장의 의미를 파악할수 없다. 오늘도 좋은 하루 입니다. 모든 데이터들을 이해해야 문자을 이해할수 있다.  이런것이 시퀀시 데이타이다. 

c8_1 이미지. 
시퀀시 데이터 의미를 파악하기 위해선, 그전의 결과값이 다음 출력값에 영향을 미치게 된다. 

c8_2 이미지, 
RNN을 구하는 함수이다. 
결과값을 구하기 위해선 그전 결과값이 영향이 주는걸 확인할수 잇다. 

c8_3 이미지. 
전에 입력했던 값에 Whh를 곱하고, 새로운 입력에 기존 W값을 곱한다. 
그리고 그 값을 더해주고, tanh하는데, 이게 (sigmoid랑 같다는데 sigmoid가 아닌가 다시 알아볼게)

lab12-1 rnn-basics
이번 시간도 rnn 에 대해서 알아본다. 

tensorflow로 rnn을 돌리때 설정들을 해주어야하는데, 그중. hidden_size라는 변수가 잇다. 

c8_4 이미지. 

* hidden_size
이 히든사이즈는 xt로 입력되는 shape의 모양에 상관없이 출력되는 shape의 배열 마지막 숫자를 같은 값으로 바꾸어준다. 
예를들어, shape = (1,1,4) 이렇게 있는데, 출력은 shape(1,1,2) 이런 형태다. 여기서 다른 값들은 상관없지만, 마지막 2의 값은 hidden size와 같은 값이다. 

c8_5이미지
* sequence_length
rnn에선 위의 그림처럼. 뉴런넷을 여러개로 펼쳐서 사용하는데, 얼마나 펼칠지 길이를 정하는게, length이다.

>시ː퀀스, sequence
영화·텔레비전에서, 몇 개의 장면이 모여 하나의 삽화를 이룬 것. 연속된 하나의 장면 설정.

* batch_size 
  문자열을 하나씩 넣으면 힘드니까 여러개 넣기위해서 배열을 하나추가해, 문자열을 넣게해줌.


lab12-2
이번시간엔 rnn을 훈련시킬거다!!!!!!!

hihello라는 문자열을. 만약 h라고 입력을 받으면 뒤에 올값이 ihello라는 값이 나올거라는걸 추측하는 알고리즘을 만들어보겟다. 

그러기위해선 우선. 
c8_6 이미지
문자열의 데이터를 one-hot incoding으로 바꾸어 주어야한다. 

c8_7 이미지 
이런식으로 입력값을 넣고 출력값을 만들어 주어야한다. 
지금 출력되야할 배열이 5개의 onehot으로 이루어져있으니까 hiden_size = 5로 해주고, 
시퀀시는 6개 이므로 sequence_length = 6
마지막으로 문자열이 hihello하나니까 1로 해준다. 

tensorflow 에선 rnn_cell = rnn_cell.BsicRNNCell(rnn_size)
여기서 rnn_size = 5 == hiden_size


lab 12-5 dynamic Rnn
rnn 의 강점은 시퀀스 데이터를 처리가능하다. 

문제 dNN 에서 loss 구하는 함수 다시 보기. 


앙상블 집에가서, 보기. 

loss 구하는 함수 보기.                                       
패딩 다시보기. 패딩은, cnn에서 이미지를 한줄 추가하는거. 
                                              